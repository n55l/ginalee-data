{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!tar xf spark-2.4.8-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!tar -xzf sql-data.tgz\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.8-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import random\n",
        "\n",
        "spark = SparkSession.builder.appName(\"YourTest\").master(\"local[2]\").config('spark.ui.port', random.randrange(4000,5000)).getOrCreate()"
      ],
      "metadata": {
        "id": "mvVvU6WgpusM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset_and_set_views():\n",
        "    global supplier, orders, customer, partsupp, nation, part\n",
        "    \n",
        "    supplier_raw = spark.read.csv(\"supplier.tbl\",sep='|',inferSchema=True).drop(\"_c7\")\n",
        "    supplier = supplier_raw.toDF(\"SuppKey\",\"Name\",\"Address\",\"NationKey\",\"Phone\",\"AcctBal\",\"Comment\").cache()\n",
        "    supplier.createOrReplaceTempView(\"supplier\")\n",
        "    \n",
        "    order_raw = spark.read.csv(\"orders.tbl\",sep='|',inferSchema=True).drop(\"_c9\")\n",
        "    orders = order_raw.toDF(\"OrderKey\",\"CustKey\",\"OrderStatus\",\"TotalPrice\",\"OrderDate\",\"Order-Pri\",\"Clerk\", \"Ship-Pri\", \"Comment\").cache()\n",
        "    orders.createOrReplaceTempView(\"orders\")\n",
        "\n",
        "    customer_raw = spark.read.csv(\"customer.tbl\",sep='|',inferSchema=True).drop(\"_c8\")\n",
        "    customer = customer_raw.toDF(\"CustKey\",\"Name\",\"Address\",\"NationKey\",\"Phone\",\"AcctBal\",\"MktSegment\", \"Comment\").cache()\n",
        "    customer.createOrReplaceTempView(\"customer\")\n",
        "    \n",
        "    partsupp_raw = spark.read.csv(\"partsupp.tbl\",sep='|',inferSchema=True).drop(\"_c5\")\n",
        "    partsupp = partsupp_raw.toDF(\"PartKey\",\"SuppKey\",\"AvailQty\",\"SupplyCost\",\"Comment\").cache()\n",
        "    partsupp.createOrReplaceTempView(\"partsupp\")\n",
        "    \n",
        "    nation_raw = spark.read.csv(\"nation.tbl\",sep='|',inferSchema=True).drop(\"_c4\")\n",
        "    nation = nation_raw.toDF(\"NationKey\",\"Name\",\"RegionKey\", \"Comment\").cache()\n",
        "    nation.createOrReplaceTempView(\"nation\")\n",
        "    \n",
        "    part_raw = spark.read.csv(\"part.tbl\",sep='|',inferSchema=True).drop(\"_c9\")\n",
        "    part = part_raw.toDF(\"PartKey\",\"Name\",\"Mfgr\",\"Brand\",\"Type\",\"Size\",\"Container\", \"RetailPrice\", \"Comment\").cache()\n",
        "    part.createOrReplaceTempView(\"part\")"
      ],
      "metadata": {
        "id": "LU4I_jwqgF0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def five_highest_totalprice_orders_sql():\n",
        "\n",
        "    five_highest_totalprice_orders = spark.sql(\"select OrderKey, OrderDate, TotalPrice from Orders order by TotalPrice desc limit 5\")\n",
        "    return five_highest_totalprice_orders"
      ],
      "metadata": {
        "id": "0AwcXpd4gKdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def five_highest_totalprice_orders_dtf():\n",
        "\n",
        "    five_highest_totalprice_orders = orders.orderBy(orders.TotalPrice.desc()).select('OrderKey', 'OrderDate', 'TotalPrice')\n",
        "    return five_highest_totalprice_orders.limit(5)"
      ],
      "metadata": {
        "id": "m2rRSGe4ttSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cust_most_recent_order_sql(custkey):\n",
        "\n",
        "    cust_most_recent_order = spark.sql(\"select Name, OrderDate, TotalPrice from Orders left\\\n",
        "     join customer C on Orders.CustKey = C.CustKey where C.CustKey = {} order by OrderDate desc limit 1\".format(custkey))\n",
        "      \n",
        "    return cust_most_recent_order"
      ],
      "metadata": {
        "id": "nQ6KNcumttVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cust_most_recent_order_dtf(custkey):\n",
        "\n",
        "    cust_most_recent_order = orders.filter(\"CustKey = {}\".format(custkey))\\\n",
        "                                   .join(customer, orders.CustKey == customer.CustKey,\"left\")\\\n",
        "                                   .select('Name', 'OrderDate', 'TotalPrice')\\\n",
        "                                   .orderBy(orders.OrderDate.desc())\n",
        "\n",
        "    return cust_most_recent_order.limit(1)"
      ],
      "metadata": {
        "id": "Bov9whj6ttYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distinct_supplied_parts(nname):\n",
        "\n",
        "    distinct_supplied_parts = spark.sql('select count(distinct P.PartKey) from partsupp P left join supplier S\\\n",
        "     on S.SuppKey = P.SuppKey where S.NationKey = (select NationKey from nation where Name = \"{}\")'.format(nname))\n",
        "\n",
        "    return distinct_supplied_parts.head()[0]"
      ],
      "metadata": {
        "id": "YCiskX6ottal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_suppliers_brand_per_nation(bname):\n",
        "\n",
        "    count_suppliers_brand_per_nation = part.filter(\"Brand = '{}'\".format(bname))\\\n",
        "                                           .join(partsupp, part.PartKey == partsupp.PartKey,\"left\")\\\n",
        "                                           .join(supplier, partsupp.SuppKey == supplier.SuppKey,\"left\")\\\n",
        "                                           .join(nation, supplier.NationKey == nation.NationKey, \"left\")\\\n",
        "                                           .groupBy(nation.Name, partsupp.SuppKey)\\\n",
        "                                           .count()\\\n",
        "                                           .groupBy(nation.Name)\\\n",
        "                                           .count()\\\n",
        "                                           .orderBy(nation.Name)\n",
        "    \n",
        "    return count_suppliers_brand_per_nation"
      ],
      "metadata": {
        "id": "qeJoRXr2t3_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def order_number_per_customer_nation(nname):\n",
        "\n",
        "    order_number_per_customer_nation = spark.sql('select year(O.OrderDate) as year, count(O.OrderKey) as num_orders from orders O left join customer C\\\n",
        "    on C.CustKey = O.CustKey where C.NationKey = (select NationKey from nation where Name = \"{}\") group by year(O.OrderDate)\\\n",
        "    order by num_orders desc'.format(nname))\n",
        "\n",
        "    return order_number_per_customer_nation"
      ],
      "metadata": {
        "id": "Xbk7dGtrt4CG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}